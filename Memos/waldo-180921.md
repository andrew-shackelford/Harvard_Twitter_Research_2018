Memo waldo180921.md

**Organization of the Repository and Data**

The directories that hold the code, documentation, and the data for the project will
be broken up into a set of directories, some of which are under revision control and 
some of which are not. This memo outlines the basic organization, at least for the start
of the project.

Note that there will be a shared Google drive that will contain all of these files. The 
shared drive will contain the master copies of all of our data, and will contain a clone of
the mainline of our code repository. If you are going to be making changes in either the
code or the data, do not do so in this directory. If you are working on code, you should
have a clone of the code in your own workspace, and merge your finished code into the mainline
in the Git repo. 

**Under Revision Control**

All of the work that will be saved and versioned under Github will live in the **Code** directory. This
obviously includes the code itself, but also includes the memos and individual notebooks for each of us.

Memos should reside in the Memos directory. They should be named following the convention last-name-of-writer+
date (so, for example, waldo180921). If someone writes multiple memos on the same day, they should be numbered
(after the first one); so this would be waldo180921-1, etc.

**Date Files**
The other top level directories will have to do with data, or configuration files used to collect the data. Configuration
files will reside in the directory ConfigFiles. These files include the filters we are using to select the tweets we grab,
as well as the credentials used to authenticate to twitter. 

Data files that are the result of the direct scraping of the twitter
stream will live in the directory CurrentData; these files will have a name that ends with the day of obtaining the
file along with a postfix that tells the type of data (so, for example, tag_data2018-09-20.json, for the raw tweets
harvested on 09/20/2018, in .json format). These files get large; once data has been extracted they will be compressed and 
moved to the directory DailyArchive. The name will remain the same with a '.Z' postfix.

Data extracted from these files will be moved to the DerivedFiles directory. If those extracts are organized by day, then
the day should be encoded in the name (much like the daily files). Most of these should be pickle files, with a .pkl 
extension. Obvious other extensions are .csv and .txt.

Just as you should not be editing the code files in the Code directory, you should not be working directly with the data
files in the data directories. Copy the files you are going to be using to a local workspace, and work with them there (this
will save you from accidentally deleting or overwriting the data files). 
